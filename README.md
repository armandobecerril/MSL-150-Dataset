# MSL-150: Mexican Sign Language (MSL) Keypoint Dataset for Domain-Specific Vocabulary

MSL-150 is a **public keypoint-only dataset** of 150 Mexican Sign Language (MSL) signs,
processed using **MediaPipe Holistic**, curated to support reproducible research in:

- Sign language recognition  
- Keypoint-based gesture modeling  
- Sequential and grammar-level sign interpretation  

This dataset is part of the doctoral research:  
**â€œRecurrent Neural Networks for the Interpretation of Mexican Sign Language in Domain-Specific Communication Scenarios.â€**

---

## ğŸ“¦ Dataset Contents (Zenodo, Full Version)

ğŸ”— **Full dataset DOI:** https://doi.org/10.5281/zenodo.17783312  
âš ï¸ *Due to size limitations, only a small demo subset is stored in GitHub.*

Zenodo includes:

- **MSL-150_keypoints.csv** â€” 226 keypoints Ã— frames per sample  
- **npz_samples/** â€” 120,000+ augmented samples (799 synthetic per class)  
- **dataset_dictionary.pdf** â€” variable and metadata glossary  
- **trained_model_v1.h5** â€” final GRU architecture  
- **model_config.json** â€” hyperparameters & training settings  

All data was extracted using **MediaPipe Holistic v0.10**.

---

## ğŸ‘¤ Signer Information

- **1 native MSL signer**  
- **150 isolated sign classes**  
- **800 original videos per class (full dataset)**  
- **799 augmented samples per class (full dataset)**  
- **200 sample excerpts per class included in GitHub (demo only)**  
- **Full HD (1080p) at 30 FPS**, controlled lighting and background  
- **226 MediaPipe keypoints per frame**

> âš ï¸ **Important:**  
> This is an **exploratory pilot dataset** recorded from a **single signer** in a **controlled environment**.  
> GitHub contains only lightweight demo samples.  
> The complete dataset must be obtained through Zenodo.

---

## ğŸ“‚ Repository Structure

```text
MSL-150/
â”œâ”€â”€ src/                     # Core Python modules (loading, training, evaluation)
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ model_lstm.py
â”‚   â”œâ”€â”€ model_gru.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ notebooks/               # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_training_LSTM.ipynb
â”‚   â””â”€â”€ 03_sequence_inference.ipynb
â”‚
â”œâ”€â”€ models/                  # Saved models, configs, and metrics
â”‚   â”œâ”€â”€ trained_model_v1.h5
â”‚   â”œâ”€â”€ model_config.json
â”‚   â””â”€â”€ metrics/
â”‚
â”œâ”€â”€ docs/                    # Diagrams, documentation, variable dictionaries
â”‚   â”œâ”€â”€ dataset_dictionary.pdf
â”‚   â””â”€â”€ pipeline_diagram.png
â”‚
â”œâ”€â”€ data/                    # Lightweight GitHub subset (ğŸ“Œ NOT the full dataset)
â”‚   â”œâ”€â”€ samples_demo/        # ~200 samples/class extracted from original dataset
â”‚   â””â”€â”€ dictionary/
â”‚       â””â”€â”€ variables.json
â”‚
â”œâ”€â”€ CITATION.cff
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE


---

## âš™ï¸ Technical Summary

- **Total Samples:** 120,000  
- **Frames per Sample:** 30  
- **Features per Frame:** 226 MediaPipe keypoints  
- **Final Tensor Shape:** `120000 Ã— 30 Ã— 226`  
- **Augmentation:** rotation, illumination, speed variation, Gaussian noise  
- **Models:** LSTM (64â€“128), GRU (64â€“128)  
- **Top model accuracy:**  
  - Validation accuracy: **0.9978**  
  - Test precision: **0.9957**  
  - Narrative sequential recall: **63.64%**

---

## âš–ï¸ License

This dataset and code are released under the **MIT License**.  
If you use this dataset, you **must** cite it.

---

## ğŸ“š How to Cite

### **BibTeX**

```bibtex
@dataset{Becerril2025_msl150,
  author = {Armando de JesÃºs Becerril Carrillo},
  title = {MSL-150: Mexican Sign Language Keypoint Dataset},
  year = {2025},
  doi = {10.5281/zenodo.17783312},
  url = {https://doi.org/10.5281/zenodo.17783312}
}
