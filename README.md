# MSL-150: Mexican Sign Language (MSL) Keypoint Dataset for Domain-Specific Vocabulary

**MSL-150** is a **public keypoint-only dataset** of *150 Mexican Sign Language (MSL) signs*,  
extracted using **MediaPipe Holistic**, designed for reproducible research in:

- Sign language recognition  
- Keypoint-based gesture modeling  
- Sequential & narrative-level sign interpretation  
- RNN/sequence models (LSTM, GRU)

This dataset is part of the doctoral research project:  
**â€œRecurrent Neural Networks for the Interpretation of Mexican Sign Language in Domain-Specific Communication Scenarios.â€**

---

## ğŸ“¦ Full Dataset (Zenodo)

ğŸ”— **DOI:** https://doi.org/10.5281/zenodo.17783312  

âš ï¸ *Due to size constraints, only a small demo subset is included in GitHub.*  
The complete dataset must be obtained from **Zenodo**.

Zenodo contains:

- **MSL-150_Mexican_Sign_Language_Dataset.csv** â€” 13.9 GB keypoint master file  
- **npz_samples/** â€” 120,000+ samples (1 original + 799 augmented per class)  
- **dataset_dictionary.pdf** â€” description of all 226 variables  
- **trained_model_v1.h5** â€” final GRU sequence model  
- **model_config.json** â€” hyperparameters & training metadata  

All keypoints were extracted using **MediaPipe Holistic v0.10**.

---

## ğŸ‘¤ Signer Information

- **1 native MSL signer**  
- **150 isolated sign classes**  
- **800 video sequences per class (full dataset)**  
- **799 augmented samples per class**  
- **200 lightweight samples/class included in GitHub (demo subset)**  
- **Full HD 1080p @ 30 FPS**, uniform lighting and background  
- **226 MediaPipe keypoints per frame**

> âš ï¸ **Important:**  
> MSL-150 is an **exploratory pilot dataset**, recorded from a **single signer** in a **controlled environment**.  
> The GitHub dataset is **only a lightweight demo subset**, intended for testing code and notebooks.  
> The full dataset must be retrieved from Zenodo.

---

## ğŸ“‚ Repository Structure

```text
MSL-150/
â”œâ”€â”€ src/                     # Core dataset & model code
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ model_lstm.py
â”‚   â”œâ”€â”€ model_gru.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ notebooks/               # Jupyter notebooks (full pipeline)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_training_LSTM.ipynb
â”‚   â””â”€â”€ 03_sequence_inference.ipynb
â”‚
â”œâ”€â”€ models/                  # Saved models, configs, metrics
â”‚   â”œâ”€â”€ trained_model_v1.h5
â”‚   â”œâ”€â”€ model_config.json
â”‚   â””â”€â”€ metrics/
â”‚
â”œâ”€â”€ docs/                    # Documentation, diagrams, dictionaries
â”‚   â”œâ”€â”€ dataset_dictionary.pdf
â”‚   â””â”€â”€ pipeline_diagram.png
â”‚
â”œâ”€â”€ data/                    # âš ï¸ Lightweight GitHub subset ONLY
â”‚   â”œâ”€â”€ samples_demo/        # ~200 samples/class extracted from the full dataset
â”‚   â””â”€â”€ dictionary/
â”‚       â””â”€â”€ variables.json
â”‚
â”œâ”€â”€ CITATION.cff
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
âš™ï¸ Technical Summary
Total Samples: 120,000

Frames per Sample: 30

Keypoints per Frame: 226

Tensor Shape: 120000 Ã— 30 Ã— 226

Augmentation:

rotation

illumination changes

temporal speed variation

Gaussian noise

Models Evaluated:

LSTM (64â€“128)

GRU (64â€“128)

Best Performing Model:

Validation accuracy: 0.9978

Test precision: 0.9957

Narrative-sequence recall: 63.64%

âš–ï¸ License
Released under the MIT License.

You may use this dataset freely for research and educational purposes.
If you use it in a publication, you must cite it.

ğŸ“š How to Cite
CITATION.cff
Located in the repository root (GitHub + Zenodo).

BibTeX Citation
bibtex
Copy code
@dataset{Becerril2025_msl150,
  author = {Armando de JesÃºs Becerril Carrillo},
  title = {MSL-150: Mexican Sign Language Keypoint Dataset},
  year = {2025},
  doi = {10.5281/zenodo.17783312},
  url = {https://doi.org/10.5281/zenodo.17783312}
}
ğŸ§© Contact
For questions, dataset issues, or collaboration opportunities:

Armando de JesÃºs Becerril Carrillo
Universidad AnÃ¡huac MÃ©xico Norte
ORCID: https://orcid.org/0009-0004-4420-1442

